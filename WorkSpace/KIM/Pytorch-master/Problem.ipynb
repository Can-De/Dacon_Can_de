{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 관련 기술들\n",
    "\n",
    "**Model 구성 시 성능향상을 위해 고려해야 하는 사항**에 대해서 알아보자.  \n",
    "아래 링크는 현재 Post에서 구현할 개념을 다룬 내용이다.<br>\n",
    "<a href=\"https://wjddyd66.github.io/dl/2019/08/31/NeuralNetwork-(5)-Others.html\">NeuralNetwork (5) 학습 관련 기술들</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cfWidCHbE40M"
   },
   "source": [
    "## 1. Settings\n",
    "### 1) Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0O_DUBzxE405"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UCLu6xWaE40-"
   },
   "source": [
    "### 2) Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JwkvjrAcE41A"
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "learning_rate = 0.0002\n",
    "num_epoch = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ObM5RlttE41E"
   },
   "source": [
    "## 2. Data\n",
    "\n",
    "### 1) Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qsdXyu5UE41F"
   },
   "outputs": [],
   "source": [
    "mnist_train = dset.MNIST(\"./\", train=True, transform=transforms.ToTensor(), target_transform=None, download=True)\n",
    "mnist_test = dset.MNIST(\"./\", train=False, transform=transforms.ToTensor(), target_transform=None, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q0rdRoNDE41J"
   },
   "source": [
    "### 2) Check Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6955,
     "status": "ok",
     "timestamp": 1559557846678,
     "user": {
      "displayName": "Choi Gunho",
      "photoUrl": "",
      "userId": "04388737836176863066"
     },
     "user_tz": -540
    },
    "id": "Tu5PcIMcE41K",
    "outputId": "1b51467c-2827-4e65-f48c-7d4609f0ac87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28]) 60000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 28, 28]), 10000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(mnist_train.__getitem__(0)[0].size(), mnist_train.__len__())\n",
    "mnist_test.__getitem__(0)[0].size(), mnist_test.__len__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u08VF2biE41Q"
   },
   "source": [
    "### 3) Set DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5PpP7pyTE41R"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(mnist_train,batch_size=batch_size, shuffle=True,num_workers=2,drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_test,batch_size=batch_size, shuffle=False,num_workers=2,drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정형화 \n",
    "\n",
    "**매우 큰 가중치가 존재**한다고 생각하면 **그 하나의 가중치에 의해서 Model이 결정**되므로 Overfitting된다고 생각할 수 있기 때문이다.  \n",
    "이러한 가중치 감소는 크게 2가지로 나뉘어 질 수 있다.  \n",
    "**1) L2 Regularization**: 가장 일반적인 regulization 기법입니다. 기존 손실함수(Lold)에 모든 학습파라메터의 제곱을 더한 식을 새로운 손실함수로 씁니다. 아래 식과 같습니다. 여기에서 1/2이 붙은 것은 미분 편의성을 고려한 것이고, λ는 패널티의 세기를 결정하는 사용자 지정 하이퍼파라메터입니다. 이 기법은 큰 값이 많이 존재하는 가중치에 제약을 주고, 가중치 값을 가능한 널리 퍼지도록 하는 효과를 냅니다.\n",
    "<p>$$W = [w_1, w_2, ... , w_n]$$</p>\n",
    "<p>$$L_{new} = L_{old} + \\frac{\\lambda}{2}(w_1^2 + w_2^2 + ... + w_n^2)$$</p>\n",
    "\n",
    "**2) L1 Regularization**: 기존 손실함수에 학습파라메터의 절대값을 더해 적용합니다. 이 기법은 학습파라메터를 sparse하게(거의 0에 가깝게) 만드는 특성이 있습니다.\n",
    "<p>$$L_{new} = L_{old} + \\lambda (\\left| w_1 \\right| + \\left| w_2 \\right| + ... + \\left| w_n \\right|)$$</p>\n",
    "\n",
    "각각의 방식을 그래프로 표현하게 되면 다음과 같다.  \n",
    "<div><img src=\"https://miro.medium.com/max/602/1*o6H_R3Do1zpch-3MZk_fjQ.png\" height=\"250\" width=\"600\" /></div>\n",
    "\n",
    "즉, **L1 Regularization에서 Sparse하다는 것은 Weight가 0으로 될 확률이 높다는 것이다.**  \n",
    "**Sparse**: 전체 w중 0이 많은 경우\n",
    "\n",
    "위의 공통된 식을 살펴보게 되면 **가중치가 큰 곳에 더 큰 Loss를 더해주는 것**이 핵심이다.  \n",
    "\n",
    "**Loss 가 커지게 되면** Gradinet Descent 를 생각하였을 때 더욱 더 빨리 최소값에 수렴하게 되고 빨리 수렴하게 되면 무한정으로 커지는 것을 막을 수 있다.  \n",
    "\n",
    "**Pytorch에서의 Weight Regularization은 weight_decay($\\lambda$) Parameter로 조절할 수 있습니다.**\n",
    "- weight_decay (float, optional) – weight decay (L2 penalty) (default: 0)\n",
    "\n",
    "**Weight_decay는 L2 Regularization으로 적용되므로 L1 Regularization으로 적용시키기 위해서는 명시적으로 손실함수에 식을 추가해야 한다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V9_keUAlE41S"
   },
   "source": [
    "### Weight Regularization Model\n",
    "\n",
    "#### 1) CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bBKru3x3E41U"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Conv2d(1,16,3,padding=1),  # 28 x 28\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16,32,3,padding=1), # 28 x 28\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),            # 14 x 14\n",
    "            nn.Conv2d(32,64,3,padding=1), # 14 x 14\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2)             #  7 x 7\n",
    "        )\n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Linear(64*7*7,100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100,10)\n",
    "        )       \n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.layer(x)\n",
    "        out = out.view(batch_size,-1)\n",
    "        out = self.fc_layer(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=0.1)</code>  \n",
    "위의 Code에서 weight_decay=0.1로 설정한다는 것은  \n",
    "L2 Regularization 식에서  \n",
    "<p>$$L_{new} = L_{old} + \\frac{\\lambda}{2}(w_1^2 + w_2^2 + ... + w_n^2)$$</p>\n",
    "$\\lambda$ = 0.1로 설정한다는 것 이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RfSDRzAqE41Y"
   },
   "source": [
    "#### 2) Loss func & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11557,
     "status": "ok",
     "timestamp": 1559557851310,
     "user": {
      "displayName": "Choi Gunho",
      "photoUrl": "",
      "userId": "04388737836176863066"
     },
     "user_tz": -540
    },
    "id": "Qev-ZYS8E41Z",
    "outputId": "1b6b86f7-b3d6-4f0d-9c63-f0665cac0c4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "model = CNN().to(device)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "# 정형화는 weight_decay로 줄 수 있습니다.\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "97_PWaomE41d"
   },
   "source": [
    "#### 3) Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 54249,
     "status": "ok",
     "timestamp": 1559557894013,
     "user": {
      "displayName": "Choi Gunho",
      "photoUrl": "",
      "userId": "04388737836176863066"
     },
     "user_tz": -540
    },
    "id": "bzrULCHKE41d",
    "outputId": "a2928b40-4a05-4fc1-aa41-5432f3171c9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3047, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_epoch):\n",
    "    for j,[image,label] in enumerate(train_loader):\n",
    "        x = image.to(device)\n",
    "        y_= label.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model.forward(x)\n",
    "        loss = loss_func(output,y_)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if i % 10 == 0:\n",
    "        print(loss)          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KFTd2eqOE41j"
   },
   "source": [
    "#### 4) Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 54854,
     "status": "ok",
     "timestamp": 1559557894635,
     "user": {
      "displayName": "Choi Gunho",
      "photoUrl": "",
      "userId": "04388737836176863066"
     },
     "user_tz": -540
    },
    "id": "PAvYqaFDE41j",
    "outputId": "5b902029-4c5d-4e79-9c50-706ca749664c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Test Data: 10.35657024383545\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "  for image,label in test_loader:\n",
    "      x = image.to(device)\n",
    "      y_= label.to(device)\n",
    "\n",
    "      output = model.forward(x)\n",
    "      _,output_index = torch.max(output,1)\n",
    "\n",
    "      total += label.size(0)\n",
    "      correct += (output_index == y_).sum().float()\n",
    "\n",
    "  print(\"Accuracy of Test Data: {}\".format(100*correct/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8T7RgTDxOIvL"
   },
   "source": [
    "### Dropout\n",
    "\n",
    "Dropout은 **Overfitting**을 막기위한 방법으로 뉴럴 네트워크가 학습중일때, 랜덤하게 뉴런을 꺼서 학습함으로써, 학습이 학습용 데이터로 치우치는 현상을 막아준다.  \n",
    "\n",
    "<div><img src=\"https://t1.daumcdn.net/cfile/tistory/224A3941583ED6B109\" height=\"250\" width=\"600\" /></div>\n",
    "\n",
    "**Pytorch에서는 model.train()으로서 Model이 Train상태일 때는 Dropout을 적용하고 model.eval()에서는 Model의 결과를 확인하므로 Dropout을 적용 안한다.**\n",
    "\n",
    "**또한 중요한점은 정형화나 Dropout의 기법은 항상 결과가 좋아지지 않는다.**  \n",
    "**기존의 Model에서 제약을 거는 것 이기 때문에 오버피팅하지 않는 상태에서 정형화나 드롭아웃을 넣으면 오히려 학습이 잘 안되는 결과가 나온다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout Model\n",
    "\n",
    "#### 1) CNN Model\n",
    "\n",
    "<code>torch.nn.Dropout2d(p=0.5, inplace=False)</code>  \n",
    "- p: Dropout 시킬 확률\n",
    "- inplace: 다른 객체를 반환하지 않고 기존 객체를 수정(Default: False)\n",
    "\n",
    "현재 FeatureMap이 2Dimension이므로 <code>nn.Dropout2d()</code>를 사용하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Conv2d(1,16,3,padding=1),  # 28\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(0.2),\n",
    "            nn.Conv2d(16,32,3,padding=1), # 28\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(0.2),\n",
    "            nn.MaxPool2d(2,2),            # 14\n",
    "            nn.Conv2d(32,64,3,padding=1), # 14\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(0.2),\n",
    "            nn.MaxPool2d(2,2)             # 7\n",
    "        )\n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Linear(64*7*7,100),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(100,10)\n",
    "        )       \n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.layer(x)\n",
    "        out = out.view(batch_size,-1)\n",
    "        out = self.fc_layer(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Loss func & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "model = CNN().to(device)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3136, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_epoch):\n",
    "    for j,[image,label] in enumerate(train_loader):\n",
    "        x = image.to(device)\n",
    "        y_= label.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model.forward(x)\n",
    "        loss = loss_func(output,y_)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if i % 10 == 0:\n",
    "        print(loss)         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Test\n",
    "\n",
    "Test하는 상태이므로 <code>model.eval()</code>을 통하여 Dropout을 적용시키지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Test Data: 9.745593070983887\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# 배치정규화나 드롭아웃은 학습할때와 테스트 할때 다르게 동작하기 때문에 모델을 evaluation 모드로 바꿔서 테스트해야합니다.\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "  for image,label in test_loader:\n",
    "      x = image.to(device)\n",
    "      y_= label.to(device)\n",
    "\n",
    "      output = model.forward(x)\n",
    "      _,output_index = torch.max(output,1)\n",
    "\n",
    "      total += label.size(0)\n",
    "      correct += (output_index == y_).sum().float()\n",
    "\n",
    "  print(\"Accuracy of Test Data: {}\".format(100*correct/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 증강\n",
    "데이터를 증가시키므로 인하여 Model의 성능을 향상시킬 수 있다.  \n",
    "\n",
    "**Image의 증가를 위해 좌우, 상하 반전, 임의의 크기로 잘라낸 다음 사이즈를 맞추는 등 많은 방법이 존재**  \n",
    "\n",
    "데이터의 증가시키는 경우 데이터가 Image이면 Pytorch에서 제공하는 **ImageFolder**함수에 넣어서 데이터를 증가시킬 수 있다.  \n",
    "\n",
    "**ImageFolder**  \n",
    "\n",
    "<div><code>torchvision.datasets.ImageFolder(root, transform=None, target_transform=None, loader=function default_loader, is_valid_file=None) </code></div>  \n",
    "\n",
    "**transform.Compose**  \n",
    "\n",
    "<div><code>torchvision.transforms.Compose(transforms)</code></div>\n",
    "\n",
    "- tranforms: list of Transform object\n",
    "\n",
    "image Tranformation을 chained together할 수 있게 해준다.\n",
    "\n",
    "**transform.Resize**  \n",
    "\n",
    "<div><code>torchvision.transforms.Resize(size, interpolation=2)</code></div>\n",
    "\n",
    "- size: 변경하고자 하는 image 크기\n",
    "- interpolation: Desired interpolation. Default is PIL.Image.BILINEAR\n",
    "\n",
    "Image 크기 변경.\n",
    "\n",
    "**transform.RandomResizedCrop**  \n",
    "\n",
    "<div><code>torchvision.transforms.RandomResizedCrop(size, scale=(0.08, 1.0), ratio=(0.75, 1.3333333333333333), interpolation=2)</code></div>\n",
    "\n",
    "- size: 샘플링할 Image 크기\n",
    "- scale: 원본 Image에서 자를 크기\n",
    "- ratio: 원본 Image에서 자른 크기에서 참조할 비율\n",
    "- interpolation – Default: PIL.Image.BILINEAR \n",
    "\n",
    "랜덤한 위치에서 샘플링.\n",
    "\n",
    "**transform.RandomHorizontalFlip**  \n",
    "\n",
    "<div><code>torchvision.transforms.RandomHorizontalFlip(p=0.5)</code></div>\n",
    "\n",
    "- p: 확률(image 좌우 반전 시킬 확률)\n",
    "\n",
    "아래 Code는 Image를 증가시키기 위하여 Image를 일정 작업을 거쳐 Return한 것 이다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "mnist_train = dset.MNIST(\"./\", train=True, \n",
    "                         transform = transforms.Compose([\n",
    "                             transforms.Resize(34),                             # 원래 28x28인 이미지를 34x34로 늘립니다.\n",
    "                             transforms.CenterCrop(28),                         # 중앙 28x28를 뽑아냅니다.\n",
    "                             transforms.RandomHorizontalFlip(),                 # 랜덤하게 좌우반전 합니다.\n",
    "                             transforms.Lambda(lambda x: x.rotate(90)),         # 람다함수를 이용해 90도 회전해줍니다.\n",
    "                             transforms.ToTensor(),                             # 이미지를 텐서로 변형합니다.\n",
    "                         ]),\n",
    "                         target_transform=None,\n",
    "                         download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(mnist_train,batch_size=batch_size, shuffle=True,num_workers=2,drop_last=True)\n",
    "\n",
    "for idx,(img,label) in enumerate(train_loader):\n",
    "  plt.imshow(img[0,0,...],cmap=\"gray\")\n",
    "  plt.show()\n",
    "  if idx > 5:\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 가중치의 초깃값\n",
    "가중치의 초기값을 무엇으로 설정 하느냐가 신경망 학습의 결과에 많은 영향을 미치기 때문에 가중치의 초기값을 어떻게 설정하는지가 Model의 결과에 영향을 많이 미친다.  \n",
    "\n",
    "**Xavier 방법**  \n",
    "<code>torch.nn.init.xavier_normal_(tensor, gain=1.0)</code>\n",
    "$$std = gain * \\sqrt{\\frac{2}{fan-in + fan-out}}$$\n",
    "\n",
    "**He 방법**  \n",
    "<code>torch.nn.init.kaiming_normal_(tensor, a=0, mode='fan_in', nonlinearity='leaky_relu')</code>\n",
    "$$std = gain * \\sqrt{\\frac{2}{(1 + \\alpha^2) * fan-in}}$$\n",
    "\n",
    "- fan-in: Input Node의 개수\n",
    "- fan-out: Output Node의 개수\n",
    "\n",
    "\n",
    "<a href=\"https://nittaku.tistory.com/269\">초기값 자세한 설명</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### He Model\n",
    "\n",
    "#### 1) CNN Model\n",
    "\n",
    "현재 **Activation Function을 ReLU를 사용하므로 가중치 초기화는 He방법 사용**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Conv2d(1,16,3,padding=1),  # 28 x 28\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16,32,3,padding=1), # 28 x 28\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),            # 14 x 14\n",
    "            nn.Conv2d(32,64,3,padding=1), # 14 x 14\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2)             #  7 x 7\n",
    "        )\n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Linear(64*7*7,100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100,10)\n",
    "        )             \n",
    "        \n",
    "        # 초기화 하는 방법\n",
    "        # 모델의 모듈을 차례대로 불러옵니다.\n",
    "        for m in self.modules():\n",
    "            # 만약 그 모듈이 nn.Conv2d인 경우\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                '''\n",
    "                # 작은 숫자로 초기화하는 방법\n",
    "                # 가중치를 평균 0, 편차 0.02로 초기화합니다.\n",
    "                # 편차를 0으로 초기화합니다.\n",
    "                m.weight.data.normal_(0.0, 0.02)\n",
    "                m.bias.data.fill_(0)\n",
    "                \n",
    "                # Xavier Initialization\n",
    "                # 모듈의 가중치를 xavier normal로 초기화합니다.\n",
    "                # 편차를 0으로 초기화합니다.\n",
    "                init.xavier_normal(m.weight.data)\n",
    "                m.bias.data.fill_(0)\n",
    "                '''\n",
    "                \n",
    "                # Kaming Initialization\n",
    "                # 모듈의 가중치를 kaming he normal로 초기화합니다.\n",
    "                # 편차를 0으로 초기화합니다.\n",
    "                init.kaiming_normal_(m.weight.data)\n",
    "                m.bias.data.fill_(0)\n",
    "            \n",
    "            # 만약 그 모듈이 nn.Linear인 경우\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                '''\n",
    "                # 작은 숫자로 초기화하는 방법\n",
    "                # 가중치를 평균 0, 편차 0.02로 초기화합니다.\n",
    "                # 편차를 0으로 초기화합니다.\n",
    "                m.weight.data.normal_(0.0, 0.02)\n",
    "                m.bias.data.fill_(0)\n",
    "                \n",
    "                # Xavier Initialization\n",
    "                # 모듈의 가중치를 xavier normal로 초기화합니다.\n",
    "                # 편차를 0으로 초기화합니다.\n",
    "                init.xavier_normal(m.weight.data)\n",
    "                m.bias.data.fill_(0)\n",
    "                '''\n",
    "                \n",
    "                # Kaming Initialization\n",
    "                # 모듈의 가중치를 kaming he normal로 초기화합니다.\n",
    "                # 편차를 0으로 초기화합니다.\n",
    "                init.kaiming_normal_(m.weight.data)\n",
    "                m.bias.data.fill_(0)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = self.layer(x)\n",
    "        out = out.view(batch_size,-1)\n",
    "        out = self.fc_layer(out)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Loss func & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "model = CNN().to(device)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8078, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_epoch):\n",
    "    for j,[image,label] in enumerate(train_loader):\n",
    "        x = image.to(device)\n",
    "        y_= label.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model.forward(x)\n",
    "        loss = loss_func(output,y_)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if i % 10 == 0:\n",
    "        print(loss)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Test Data: 11.929086685180664\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "  for image,label in test_loader:\n",
    "      x = image.to(device)\n",
    "      y_= label.to(device)\n",
    "\n",
    "      output = model.forward(x)\n",
    "      _,output_index = torch.max(output,1)\n",
    "\n",
    "      total += label.size(0)\n",
    "      correct += (output_index == y_).sum().float()\n",
    "\n",
    "  print(\"Accuracy of Test Data: {}\".format(100*correct/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습률\n",
    "<a href=\"https://wjddyd66.github.io/dl/2019/07/26/NeuralNetwork-(3)-Optimazation.html\">NeuralNetwork (3) Optimazation</a>를 보게 되면 Normal Equation과 Gradient Descent비교에서 **Feature가 많이 존재하더라도 학습할 수 있다는 장점**이 존재하고 **대신 Learning Rate를 잘 설정해야 한다는 단점**이 있다고 올렸었다.  \n",
    "Learning Rate가 너무 크면 발산하게 되고, 너무 작으면 최적의 Weight로서 Update하는데너무 오래 걸릴 가능성이 있다.  \n",
    "아래 사진을 보게 되면 학습률에 대한 손실 그래프를 보여준다.  \n",
    "\n",
    "<div><img src=\"https://raw.githubusercontent.com/wjddyd66/wjddyd66.github.io/master/static/img/AI/130.PNG\" height=\"250\" width=\"600\" /></div>\n",
    "\n",
    "따라서 실질적으로 Learning Rate를 크게 설정하고 점차 줄여가는 방안으로서 학습하였었다.  \n",
    "\n",
    "Pytorch에서는 이러한 Learning Rate를 여러번의 Trainning이 아닌 **학습률을 점차 떨어뜨리는 방법**으로서 구현하였다.  \n",
    "\n",
    "<code>torch.optim.lr_scheduler.StepLR(optimizer, step_size, gamma=0.1, last_epoch=-1)</code>\n",
    "- optimizer(Optimizer): Optimizer\n",
    "- step_size(int): Period of learning rate decay\n",
    "- gamma(float): Multiplicative factor of learning rate decay\n",
    "- last_epoch(int): The index of last epoch. Default: -1\n",
    "정해진 Step_size마다 Learning Rate에 gamma를 곱하여 Learning Rate를 감소\n",
    "\n",
    "<code>torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones, gamma=0.1, last_epoch=-1)</code>\n",
    "- optimizer(Optimizer): Optimizer\n",
    "- milestones (list) – List of epoch indices. Must be increasing.\n",
    "- gamma(float): Multiplicative factor of learning rate decay\n",
    "- last_epoch(int): The index of last epoch. Default: -1\n",
    "Step_size를 List로서 받아서 원하는 지점마다 학습률을 감소\n",
    "\n",
    "<code>torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma, last_epoch=-1)</code>\n",
    "- optimizer(Optimizer): Optimizer\n",
    "- gamma(float): Multiplicative factor of learning rate decay\n",
    "- last_epoch(int): The index of last epoch. Default: -1\n",
    "매 Epoch마다 Learning Rate에 gamma를 곱하여 Learning Rate를 감소"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ExponentialLR Model\n",
    "\n",
    "#### 1) CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Conv2d(1,16,3,padding=1),  # 28 x 28\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16,32,3,padding=1), # 28 x 28\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),            # 14 x 14\n",
    "            nn.Conv2d(32,64,3,padding=1), # 14 x 14\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2)             #  7 x 7\n",
    "        )\n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Linear(64*7*7,100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100,10)\n",
    "        )        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.layer(x)\n",
    "        out = out.view(batch_size,-1)\n",
    "        out = self.fc_layer(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Loss func & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_step_count', 'base_lrs', 'gamma', 'get_lr', 'last_epoch', 'load_state_dict', 'optimizer', 'state_dict', 'step']\n",
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_step_count', 'add_param_group', 'defaults', 'load_state_dict', 'param_groups', 'state', 'state_dict', 'step', 'zero_grad']\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "model = CNN().to(device)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 지정한 스텝 단위로 학습률에 감마를 곱해 학습률을 감소시킵니다.\n",
    "#scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma= 0.99)       \n",
    "\n",
    "# 지정한 스텝 지점(예시에서는 10,30,80)마다 학습률에 감마를 곱해줍니다.\n",
    "#scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[10,30,80], gamma= 0.1)  \n",
    "\n",
    "# 매 epoch마다 학습률에 감마를 곱해줍니다.\n",
    "scheduler = lr_scheduler.ExponentialLR(optimizer, gamma= 0.99)                             \n",
    "\n",
    "print(dir(scheduler))\n",
    "print(dir(optimizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/theia/.local/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:82: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3146, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch: 0, Learning Rate: 0.00019800000000000002\n",
      "Epoch: 1, Learning Rate: 0.00019602\n",
      "Epoch: 2, Learning Rate: 0.0001940598\n",
      "Epoch: 3, Learning Rate: 0.000192119202\n",
      "Epoch: 4, Learning Rate: 0.00019019800998\n",
      "Epoch: 5, Learning Rate: 0.0001882960298802\n",
      "Epoch: 6, Learning Rate: 0.00018641306958139798\n",
      "Epoch: 7, Learning Rate: 0.00018454893888558403\n",
      "Epoch: 8, Learning Rate: 0.00018270344949672818\n",
      "Epoch: 9, Learning Rate: 0.00018087641500176088\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_epoch):\n",
    "    scheduler.step()  \n",
    "    for j,[image,label] in enumerate(train_loader):\n",
    "        x = image.to(device)\n",
    "        y_= label.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model.forward(x)\n",
    "        loss = loss_func(output,y_)\n",
    "        loss.backward()\n",
    "          \n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print(loss)   \n",
    "            \n",
    "    #print(\"Epoch: {}, Learning Rate: {}\".format(i,scheduler.get_lr()))  \n",
    "    print(\"Epoch: {}, Learning Rate: {}\".format(i,scheduler.optimizer.state_dict()['param_groups'][0]['lr']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Test Data: 11.648637771606445\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "  for image,label in test_loader:\n",
    "      x = image.to(device)\n",
    "      y_= label.to(device)\n",
    "\n",
    "      output = model.forward(x)\n",
    "      _,output_index = torch.max(output,1)\n",
    "\n",
    "      total += label.size(0)\n",
    "      correct += (output_index == y_).sum().float()\n",
    "\n",
    "  print(\"Accuracy of Test Data: {}\".format(100*correct/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization\n",
    "정규화의 종류로는 크게 2가지가 존재한다.\n",
    "- 표준 정규화: $\\hat{x} = \\frac{x - m}{\\alpha}$\n",
    "- 최소극대화 정규화: $x = (x - min(x))/(max(x) - min(x))$\n",
    "\n",
    "**정규화의 문제로는 너무 작거나 큰 이상치가 있는 경우에는 오히려 학습에 방해가 되는 경우도 발생한다.**  \n",
    "\n",
    "아래 그림은 정규화를 하였을때 장점중 하나를 표현한 것이다.\n",
    "<div><img src=\"http://jsideas.net/assets/img/20180128.png\" height=\"250\" width=\"600\" /></div>\n",
    "\n",
    "위의 그림과 같이 데이터의 각 요소별 범위가 같은 비율로서 Update함으로써 더 빠른 Update를 기대할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization Model\n",
    "\n",
    "#### 1) 데이터 정규화\n",
    "transforms.Normalization을 통화여 정규화가 가능하다.  \n",
    "각각의 Parameter가 여러개인 것은 들어오는 Input Image의 Channel을 모르기 때문이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = dset.MNIST(\"./\", train=True, \n",
    "                         transform=transforms.Compose([\n",
    "                             transforms.ToTensor(),\n",
    "                             transforms.Normalize(mean=(0.1307,), std=(0.3081,))\n",
    "                         ]),\n",
    "                         target_transform=None, \n",
    "                         download=True)\n",
    "mnist_test = dset.MNIST(\"./\", train=False, \n",
    "                        transform=transforms.Compose([\n",
    "                             transforms.ToTensor(),\n",
    "                             transforms.Normalize(mean=(0.1307,), std=(0.3081,))\n",
    "                        ]),\n",
    "                        target_transform=None, \n",
    "                        download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(mnist_train,batch_size=batch_size, shuffle=True,num_workers=2,drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_test,batch_size=batch_size, shuffle=False,num_workers=2,drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Conv2d(1,16,3,padding=1),  # 28 x 28\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16,32,3,padding=1), # 28 x 28\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),            # 14 x 14\n",
    "            nn.Conv2d(32,64,3,padding=1), # 14 x 14\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2)             #  7 x 7\n",
    "        )\n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Linear(64*7*7,100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100,10)\n",
    "        )        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.layer(x)\n",
    "        out = out.view(batch_size,-1)\n",
    "        out = self.fc_layer(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Loss func & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "model = CNN().to(device)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2997, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_epoch):\n",
    "    for j,[image,label] in enumerate(train_loader):\n",
    "        x = image.to(device)\n",
    "        y_= label.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model.forward(x)\n",
    "        loss = loss_func(output,y_)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if i % 10 == 0:\n",
    "        print(loss)          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5) Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Test Data: 34.15464782714844\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "  for image,label in test_loader:\n",
    "      x = image.to(device)\n",
    "      y_= label.to(device)\n",
    "\n",
    "      output = model.forward(x)\n",
    "      _,output_index = torch.max(output,1)\n",
    "\n",
    "      total += label.size(0)\n",
    "      correct += (output_index == y_).sum().float()\n",
    "\n",
    "  print(\"Accuracy of Test Data: {}\".format(100*correct/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Normalization\n",
    "\n",
    "**배치 정규화**는 활성함수의 활성화값 또는 출력값을 정규화 하는 작업을 의미한다. 이는 데이터 분포가 치우치는 현상을 해결함으로써 가중치가 엉뚱한 방향으로 갱신될 문제를 해결할 수 있다.  \n",
    "\n",
    "배치 정규화의 과정은 아래와 같은 그림으로 나타낼 수 있다.  \n",
    "\n",
    "<div><img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile29.uf.tistory.com%2Fimage%2F994586445BBE000E15CC3D\" height=\"250\" width=\"600\" /></div>\n",
    "\n",
    "위의 그림으로서 데이터의 분포가 평균이 0, 분산이 1이 되도록 정규화를 한다.  \n",
    "수식으로는 아래와 같이 나타낼 수 있다.  \n",
    "\n",
    "<p>$$ \\mu_B \\leftarrow \\frac{1}{m}\\sum_{i=1}^m x_i$$</p>\n",
    "<p>$$ \\sigma_B^2 \\leftarrow \\frac{1}{m}\\sum_{i=1}^m (x_i-\\mu_B)^2$$</p>\n",
    "<p>$$ \\hat{x_i} \\leftarrow \\frac{x_i-\\mu_B}{\\sqrt{\\sigma_B^2 + \\varepsilon}}$$</p>\n",
    "<p>$$ B = {x_1, x_2, ... , x_m} $$</p>\n",
    "\n",
    "위의 식에서 알 수 있듯이 m개의 입력 데이터의 집합에 대해 평균 <span>$ \\mu_B$</span>와 분산<span>$ \\sigma_B^2$</span>를 구한다.  \n",
    "그리고 입력 데이터를 평균이 0, 분산이 1이 되게 정규화를 실시한다.  \n",
    "<span>$ \\varepsilon $</span>는 매우 작은 값으로서 <span>$\\frac{x_i-\\mu_B}{\\sqrt{\\sigma_B^2 + \\varepsilon}} $</span>의 값이 inf가 되는 것을 방지한다.  \n",
    "\n",
    "Pytorch에서는 nn.BatchNorm()으로서 구성한다.  \n",
    "또한 **DropOut기법과 똑같이 Train에서는 BatchNormalization을 실시하고 평가할때는 model.eval()을 통하여 BatchNormalization을 실시하지 않는다.**  \n",
    "\n",
    "**위에서도 알 수 있듯이 Normalization은 Train Dataset과 Test Dataset을 똑같이 Normalization을 시켜서 Update하는 거라면 Batch Normalization은 같은 Batch Data끼리의 Normalization을 통하여 Update하는 것 이다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Normalization Model\n",
    "\n",
    "#### 1) 데이터 Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = dset.MNIST(\"./\", train=True, transform=transforms.ToTensor(), target_transform=None, download=True)\n",
    "mnist_test = dset.MNIST(\"./\", train=False, transform=transforms.ToTensor(), target_transform=None, download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(mnist_train,batch_size=batch_size, shuffle=True,num_workers=2,drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_test,batch_size=batch_size, shuffle=False,num_workers=2,drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 데이터를 정규화하는것처럼 연산을 통과한 결과값을 정규화할 수 있습니다.\n",
    "# 그 다양한 방법중에 대표적인것이 바로 Batch Normalization이고 이는 컨볼루션 연산처럼 모델에 한 층으로 구현할 수 있습니다.\n",
    "# https://pytorch.org/docs/stable/nn.html?highlight=batchnorm#torch.nn.BatchNorm2d\n",
    "# nn.BatchNorm2d(x)에서 x는 입력으로 들어오는 채널의 개수입니다.\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Conv2d(1,16,3,padding=1),  # 28 x 28\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16,32,3,padding=1), # 28 x 28\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),            # 14 x 14\n",
    "            nn.Conv2d(32,64,3,padding=1), # 14 x 14\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2)             #  7 x 7\n",
    "        )\n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Linear(64*7*7,100),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100,10)\n",
    "        )       \n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.layer(x)\n",
    "        out = out.view(batch_size,-1)\n",
    "        out = self.fc_layer(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Loss func & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "model = CNN().to(device)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5503, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_epoch):\n",
    "    for j,[image,label] in enumerate(train_loader):\n",
    "        x = image.to(device)\n",
    "        y_= label.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model.forward(x)\n",
    "        loss = loss_func(output,y_)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if i % 10 == 0:\n",
    "        print(loss)                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5) Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Test Data: 92.7383804321289\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# 배치정규화나 드롭아웃은 학습할때와 테스트 할때 다르게 동작하기 때문에 모델을 evaluation 모드로 바꿔서 테스트해야합니다.\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "  for image,label in test_loader:\n",
    "      x = image.to(device)\n",
    "      y_= label.to(device)\n",
    "\n",
    "      output = model.forward(x)\n",
    "      _,output_index = torch.max(output,1)\n",
    "\n",
    "      total += label.size(0)\n",
    "      correct += (output_index == y_).sum().float()\n",
    "\n",
    "  print(\"Accuracy of Test Data: {}\".format(100*correct/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다양한 Optimazation\n",
    "<a href=\"https://wjddyd66.github.io/dl/2019/07/26/NeuralNetwork-(3)-Optimazation2.html\">NeuralNetwork (3) Optimazation2</a>에 Optimizer가 고려해야 하는 사항과 다양한 Optimizer를 소개하였다.  \n",
    "Pytorch에서는 torch.optim에서 이러한 종류를 구현하여서 제공하고 있다.\n",
    "\n",
    "**SGD**  \n",
    "<code>torch.optim.SGD(params, lr=required parameter, momentum=0, dampening=0, weight_decay=0, nesterov=False)</code>\n",
    "\n",
    "**AdaGrad**  \n",
    "<code>torch.optim.Adagrad(params, lr=0.01, lr_decay=0, weight_decay=0, initial_accumulator_value=0)</code>\n",
    "\n",
    "**RMS Prop**  \n",
    "<code>torch.optim.RMSprop(params, lr=0.01, alpha=0.99, eps=1e-08, weight_decay=0, momentum=0, centered=False)</code>\n",
    "\n",
    "**Adam**  \n",
    "<code>torch.optim.Adam(params, lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)</code>"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "7.2 정형화(Weight_Regularization).ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
